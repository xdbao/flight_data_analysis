{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b707c957",
   "metadata": {},
   "source": [
    "# ST2195 Coursework\n",
    "## Loading libraries and data\n",
    "#### Load all libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import calplot\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from sklearn import *\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV      \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9666935",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6b515",
   "metadata": {},
   "source": [
    "Download airports.csv, carriers.csv, plane-data.csv, 2006.csv.bz2, and 2007.csv.bz2 from the Harvard dataverse at <https://doi.org/10.7910/DVN/HG7NV7>. Save the files in a folder called <code> dataverse_files </code>. Create data frames called <code>airports</code> with airports.csv, <code>carriers</code> with carriers.csv, and <code>planes</code> with plane-data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(\"./dataverse_files/airports.csv\")\n",
    "carriers = pd.read_csv(\"./dataverse_files/carriers.csv\")\n",
    "planes = pd.read_csv(\"./dataverse_files/plane-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44aea3",
   "metadata": {},
   "source": [
    "Create data frame called <code>ontime</code> with 2006.csv.bz2, 2007.csv.bz2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14139ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./dataverse_files\"\n",
    "files = glob.glob(path + \"/*.csv.bz2\")\n",
    "\n",
    "l = []\n",
    "\n",
    "for f in files:\n",
    "    tempontime = pd.read_csv(f)\n",
    "    l.append(tempontime)\n",
    "    print(f'Data frame for {f}, is successfully created with shape {tempontime.shape}')\n",
    "    ontime = pd.concat(l, axis=0)\n",
    "    \n",
    "    print(ontime.shape)\n",
    "    ontime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9bff39",
   "metadata": {},
   "source": [
    "In the <code>ontime</code> data frame, convert all the column names into lower case. Remove duplicated rows. \n",
    "Rename <code> dayofmonth </code> column as <code>day</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50538a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime = ontime.rename(columns = str.lower)\n",
    "ontime.drop_duplicates(keep = \"first\", inplace = True)\n",
    "ontime.rename(columns = {\"dayofmonth\":\"day\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee562935",
   "metadata": {},
   "source": [
    "Convert the values in <code> month </code> and <code> day </code> as 2 digits.  Create a new column called <code> date </code> in year-month-day format.Concatenate the values of year,month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ontime[[\"month\", \"day\"]]:   \n",
    "    ontime[column] = ontime[column].apply(lambda x: str(x).zfill(2))\n",
    "\n",
    "ontime[\"date\"] = ontime[\"year\"].astype(str) + ontime[\"month\"]+ ontime[\"day\"]\n",
    "ontime[\"date\"] = pd.to_datetime(ontime[\"date\"], format= \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898538f7",
   "metadata": {},
   "source": [
    "Drop non-applicable values in <code> deptime, arrtime, crsdeptime and crsarrtime </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime.dropna(subset=[\"deptime\", \"arrtime\",\"crsdeptime\",\"crsarrtime\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97a55f",
   "metadata": {},
   "source": [
    "Convert the timing of departure, arrival, scheduled departure and scheduled arrival timing from 2400 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d68ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ontime[[\"deptime\", \"arrtime\",\"crsdeptime\",\"crsarrtime\"]]:   \n",
    "    ontime[column] = ontime[column].apply(lambda x: str(x))\n",
    "\n",
    "for column in ontime[[\"deptime\", \"arrtime\",\"crsdeptime\",\"crsarrtime\"]]:\n",
    "    ontime.loc[ontime[column] == \"2400\", column] = \"0\"\n",
    "    \n",
    "ontime = ontime.astype({\"deptime\":\"float\",\"arrtime\":\"float\", \"crsdeptime\":\"float\",\"crsarrtime\":\"float\"})\n",
    "ontime = ontime.astype({\"deptime\":\"int\",\"arrtime\":\"int\", \"crsdeptime\":\"int\",\"crsarrtime\":\"int\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85673771",
   "metadata": {},
   "source": [
    "Now, exclude all the departure, arrival, scheduled departure and scheduled arrival timing more than 2400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ontime[[\"deptime\", \"arrtime\",\"crsdeptime\",\"crsarrtime\"]]:\n",
    "    ontime = ontime[ontime[column] < 2400] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a46c6",
   "metadata": {},
   "source": [
    "Divide time into 4-hours intervals and name the intervals as [00:00-04:00), [04:00-08:00), [08:00-12:00) ,\n",
    "[12:00-16:00), [16:00-20:00) , [20:00-24:00)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e36a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime[\"deptimeintervals\"] = pd.cut(x = ontime[\"deptime\"], right = False, \n",
    "                                    bins = [0,400,800,1200,1600,2000,2400],\n",
    "                                    labels = [\"[00:00-04:00)\",\"[04:00-08:00)\",\"[08:00-12:00)\",\n",
    "                                              \"[12:00-16:00)\",\"[16:00-20:00)\", \"[20:00-24:00)\"])\n",
    "\n",
    "ontime[\"arrtimeintervals\"] = pd.cut(x = ontime[\"arrtime\"], right = False, \n",
    "                                    bins = [0,400,800,1200,1600,2000,2400],\n",
    "                                    labels = [\"[00:00-04:00)\",\"[04:00-08:00)\",\"[08:00-12:00)\",\n",
    "                                              \"[12:00-16:00)\",\"[16:00-20:00)\", \"[20:00-24:00)\"])\n",
    "        \n",
    "ontime[\"crsdeptimeintervals\"] = pd.cut(x = ontime[\"crsdeptime\"], right = False, \n",
    "                                       bins = [0,400,800,1200,1600,2000,2400],\n",
    "                                       labels = [\"[00:00-04:00)\",\"[04:00-08:00)\",\"[08:00-12:00)\",\n",
    "                                                 \"[12:00-16:00)\",\"[16:00-20:00)\", \"[20:00-24:00)\"])\n",
    "\n",
    "ontime[\"crsarrtimeintervals\"] = pd.cut(x = ontime[\"crsarrtime\"], right = False, \n",
    "                                       bins = [0,400,800,1200,1600,2000,2400],\n",
    "                                       labels = [\"[00:00-04:00)\",\"[04:00-08:00)\",\"[08:00-12:00)\",\n",
    "                                                 \"[12:00-16:00)\",\"[16:00-20:00)\", \"[20:00-24:00)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050597cd",
   "metadata": {},
   "source": [
    "Make sure there are 4 digits in <code> deptime </code> , <code> arrtime </code>, <code> crsdeptime </code> and <code> crsarrtime </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ontime[[\"deptime\", \"arrtime\",\"crsdeptime\",\"crsarrtime\"]]:   \n",
    "    ontime[column] = ontime[column].apply(lambda x: str(x).zfill(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3406da",
   "metadata": {},
   "source": [
    "Convert <code>deptime, arrtime, crsdeptime and crsarrtime </code> into hours and minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43abc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime[\"dephour\"] = ontime.deptime.str[:2]\n",
    "ontime[\"depmin\"] = ontime.deptime.str[2:]\n",
    "ontime[\"crsdephour\"] = ontime.crsdeptime.str[:2]\n",
    "ontime[\"crsdepmin\"] = ontime.crsdeptime.str[2:]\n",
    "ontime[\"arrhour\"] = ontime.arrtime.str[:2]\n",
    "ontime[\"arrmin\"] = ontime.arrtime.str[2:]\n",
    "ontime[\"crsarrhour\"] = ontime.crsarrtime.str[:2]\n",
    "ontime[\"crsarrmin\"] = ontime.crsarrtime.str[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e62a0",
   "metadata": {},
   "source": [
    "Convert <code>deptime, arrtime, crsdeptime and crsarrtime </code> into hours:minutes format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime[\"deptime\"] = pd.to_datetime(ontime[\"dephour\"] + \":\" \n",
    "                                   + ontime[\"depmin\"], format=\"%H:%M\").dt.time\n",
    "ontime[\"arrtime\"] = pd.to_datetime(ontime[\"arrhour\"] + \":\" \n",
    "                                   + ontime[\"arrmin\"], format=\"%H:%M\").dt.time\n",
    "ontime[\"crsdeptime\"] = pd.to_datetime(ontime[\"crsdephour\"] + \":\" \n",
    "                                   + ontime[\"crsdepmin\"], format=\"%H:%M\").dt.time\n",
    "ontime[\"crsarrtime\"] = pd.to_datetime(ontime[\"crsarrhour\"] + \":\" \n",
    "                                   + ontime[\"crsarrmin\"], format=\"%H:%M\").dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09757a5",
   "metadata": {},
   "source": [
    "Convert <code>deptime, arrtime, crsdeptime and crsarrtime</code> to timedelta64[ns] data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime[\"deptime2\"] = pd.to_timedelta(pd.to_datetime(ontime[\"deptime\"],format='%H:%M:%S').\n",
    "                                     dt.strftime('%H:%M:%S'))\n",
    "ontime[\"arrtime2\"] = pd.to_timedelta(pd.to_datetime(ontime[\"arrtime\"],format='%H:%M:%S').\n",
    "                                     dt.strftime('%H:%M:%S'))\n",
    "ontime[\"crsdeptime2\"] = pd.to_timedelta(pd.to_datetime(ontime[\"crsdeptime\"],format='%H:%M:%S').\n",
    "                                        dt.strftime('%H:%M:%S'))\n",
    "ontime[\"crsarrtime2\"] = pd.to_timedelta(pd.to_datetime(ontime[\"crsarrtime\"],format='%H:%M:%S').\n",
    "                                        dt.strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef06b15",
   "metadata": {},
   "source": [
    "Concatenate <code> date </code> with <code> deptime, arrtime, crsdeptime, and crsarrtime </code> respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime[\"datedeptime\"] = ontime[\"year\"].astype(str) + (ontime[\"month\"] + ontime[\"day\"]+ ontime[\"dephour\"] \n",
    "                                                      + ontime[\"depmin\"])\n",
    "ontime[\"datearrtime\"] = ontime[\"year\"].astype(str) + (ontime[\"month\"] + ontime[\"day\"]+ ontime[\"arrhour\"] \n",
    "                                                      + ontime[\"arrmin\"])\n",
    "ontime[\"datecrsdeptime\"] = ontime[\"year\"].astype(str) + (ontime[\"month\"] + ontime[\"day\"]+ ontime[\"crsdephour\"] \n",
    "                                                         + ontime[\"crsdepmin\"])\n",
    "ontime[\"datecrsarrtime\"] = ontime[\"year\"].astype(str) + (ontime[\"month\"] + ontime[\"day\"]+ ontime[\"crsarrhour\"]\n",
    "                                                         + ontime[\"crsarrmin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a19142",
   "metadata": {},
   "source": [
    "Convert <code> datedeptime, datearrtime, datecrsdeptime and datecrsarrtime </code> into datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99646911",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ontime[[\"datedeptime\", \"datearrtime\",\"datecrsdeptime\",\"datecrsarrtime\"]]:\n",
    "    ontime[column] = pd.to_datetime(ontime[column], format=\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f79d8",
   "metadata": {},
   "source": [
    "Create <code>biarrdelay</code> columns with value of 1 indicating delay and 0 depicting no delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of conditions\n",
    "condition = [(ontime[\"arrdelay\"] <= 0),(ontime[\"arrdelay\"] > 0)]\n",
    "\n",
    "# A list of valus to assign for each condition\n",
    "values = [0, 1]\n",
    "\n",
    "# Assign values in the list based on conditions using np.select\n",
    "ontime[\"biarrdelay\"] = np.select(condition, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27014465",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7a309",
   "metadata": {},
   "source": [
    "# 1.When is the best time of day, day of week and time of the year to fly to minimize delay?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93696ac3",
   "metadata": {},
   "source": [
    "### Idea: Only arrival delays are considered as departure delay did not necessarily result in arrival delay. Average arrival delays are computed for each date, month, day of week and each time interval to identify the period with shortest average arrival delay to fly to minimize delays.\n",
    "\n",
    "### a. Calendar plots for average daily arrival delay for 2006 and 2007\n",
    "\n",
    "For computation of arrival delay, drop non-applicable arrival delay values in ontime.\n",
    "Filter out diverted and canceled flights. When the flight arrives early, it has a negative value. \n",
    "Replace all negative values of arrdelay columns with 0 to indicate no delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime1 = ontime.dropna(subset=[\"arrdelay\"])\n",
    "\n",
    "ontime1[\"cancelled\"] = ontime1[\"cancelled\"].apply(lambda x: str(x))\n",
    "ontime1 = ontime1[ontime1[\"cancelled\"] == \"0\"]\n",
    "\n",
    "ontime1[\"diverted\"] = ontime1[\"diverted\"].apply(lambda x: str(x))\n",
    "ontime1 = ontime1[ontime1[\"diverted\"] == \"0\"]\n",
    "\n",
    "ontime1[\"depdelay\"] = ontime1[\"depdelay\"].apply(lambda x: 0 if x < 0 else x)\n",
    "ontime1[\"arrdelay\"] = ontime1[\"arrdelay\"].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7235cd",
   "metadata": {},
   "source": [
    "Group by date and compute average daily arrival delay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c264140",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgarrdelay = ontime1.groupby(ontime[\"date\"])[\"arrdelay\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ba386",
   "metadata": {},
   "source": [
    "Use calplot package to generate a calendar plot with data arranged in series such that date is the index and \n",
    "daily average arrival delay are the values.Use YlOrRD color palettes to demonstrate \n",
    "the length of daily arrival delay.Each rectangle of the calendar represents a day of the year. The color of each rectangle is determined by the \n",
    "length of average daily arrival delays. Shade of dark red demonstrates long average daily arrival delay whereas \n",
    "shade of light yellow depicts short average daily arrival delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "calplot.calplot(avgarrdelay, cmap = \"YlOrRd\", suptitle = \"Average Arrival Delay from 2006 to 2007 (minutes)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a24581",
   "metadata": {},
   "source": [
    "### b. Bar plots for average monthly arrival delay for 2006 and 2007\n",
    "Group by month and calculate average arrival delay for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c94800",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgarrdelaymonthly = (ontime1.groupby(ontime[\"date\"].dt.strftime(\"%b\"))[\"arrdelay\"].mean().sort_values(ascending = False))\n",
    "avgarrdelaymonthly = pd.DataFrame({\"month\":avgarrdelaymonthly.index, \n",
    "                                   \"monthlyavgarrdelay\":avgarrdelaymonthly.values})\n",
    "avgarrdelaymonthly[\"monthlyavgarrdelay\"] = avgarrdelaymonthly[\"monthlyavgarrdelay\"].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc277d3",
   "metadata": {},
   "source": [
    "Define a function called <code> addlabels( ) </code> for labels of bar charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138cb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i]+0.2, y[i], ha = \"center\", fontsize = 11, fontname = \"sans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2558f",
   "metadata": {},
   "source": [
    "Generate the bar plots of monthly average arrival delay with Paired color palettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(avgarrdelaymonthly.month,avgarrdelaymonthly.monthlyavgarrdelay, color = col_map.colors, \n",
    "       edgecolor = \"white\",width = 0.8)\n",
    "ax.set_title(\"Average Arrival Delay per Month\", fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "ax.set_xlabel(\"Month\", fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "ax.set_ylabel(\"Average Arrival Delay (minutes)\", fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "\n",
    "addlabels(avgarrdelaymonthly.month,avgarrdelaymonthly.monthlyavgarrdelay)\n",
    "\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feace0db",
   "metadata": {},
   "source": [
    "### c. Bar plots of daily average arrival delay from 2006 to 2007.\n",
    "\n",
    "Group by day of the week and calculate average arrival delay for each day of week. Remove non-applicable values. The days of the week are Monday, Tuesday, Wednesday, Thursday, Friday, Saturday and Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ef6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgarrdelaydaily = (ontime1.groupby(ontime[\"date\"].dt.strftime(\"%a\"))[\"arrdelay\"].mean().\n",
    "                    sort_values(ascending = False))\n",
    "avgarrdelaydaily = pd.DataFrame({\"dayofweek\":avgarrdelaydaily.index, \n",
    "                                 \"dailyavgarrdelay\":avgarrdelaydaily.values})\n",
    "avgarrdelaydaily[\"dailyavgarrdelay\"] = avgarrdelaydaily[\"dailyavgarrdelay\"].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d18f3",
   "metadata": {},
   "source": [
    "Generate the bar plots of average arrival delay for day of week from 2006 to 2007 with Paired color palettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(avgarrdelaydaily.dayofweek,avgarrdelaydaily.dailyavgarrdelay, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Average Arrival Delay per Day of Week\", fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "ax.set_xlabel(\"Day of Week\", fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "ax.set_ylabel(\"Average Arrival Delay (minutes)\", fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "addlabels(avgarrdelaydaily.dayofweek,avgarrdelaydaily.dailyavgarrdelay)\n",
    "\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c67fe2",
   "metadata": {},
   "source": [
    "### d. Bar plots of average departure and arrival delays for each time interval from 2006 to 2007.\n",
    "\n",
    "Group by arrival time intervals and calculate average arrival delay for each time interval. Remove non-applicable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgarrdelaytime = ontime1.groupby(ontime[\"arrtimeintervals\"])[\"arrdelay\"].mean().sort_values(ascending = False)\n",
    "avgarrdelaytime = pd.DataFrame({\"arrtimeintervals\":avgarrdelaytime.index, \n",
    "                                \"timeavgarrdelay\":avgarrdelaytime.values})\n",
    "avgarrdelaytime[\"timeavgarrdelay\"] = avgarrdelaytime[\"timeavgarrdelay\"].apply(lambda x: round(x, 2))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a73b5",
   "metadata": {},
   "source": [
    "Generate the bar plots of average arrival delays of each time interval from 2006 to 2007 with Paired color palettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(avgarrdelaytime.arrtimeintervals,avgarrdelaytime.timeavgarrdelay, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Average Arrival Delay per Time Interval\", fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "ax.set_xlabel(\"Time Intervals\", fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "ax.set_ylabel(\"Average Arrival Delay (minutes)\", fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "addlabels(avgarrdelaytime.arrtimeintervals,avgarrdelaytime.timeavgarrdelay)\n",
    "\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15,\n",
    "          rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.ylim([0, 83])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e01c7f",
   "metadata": {},
   "source": [
    "# 2. Do older planes suffer more delays?\n",
    "\n",
    "### Idea: Determine age of plane with manufacturing year. Arrival delay ratio for each manufacturing year is computed and plotted with scatter plots fitted with the best fit line. Results from the linear regression model are analyzed to recognize the relationship between manufacturing year and arrival delay ratio.\n",
    "\n",
    "### a. Scatter plots for ratios of arrival delays are generated against manufacturing years\n",
    "\n",
    "The age of the planes is determined by manufacturing year, which is <code> year </code> column in <code>planes </code>data frame. Rename year column as <code> manufaturingyear </code>. Drop blanks and \"None\" in <code> manufaturingyear </code> column in planes data frame. Convert the values of <code> manufaturingyear </code> as integer. Then drop value of 0 in <code>manufacturingyear</code> .Inner join <code>planes</code> with <code>ontime1</code> where diverted and canceled flights are filtered out from <code>ontime</code> by <code>tailnum</code> for computation of arrival delay ratio based on manufacturing year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "planes.rename(columns={\"year\":\"manufacturingyear\"}, inplace=True)\n",
    "planes = planes[planes[\"manufacturingyear\"].notna()]\n",
    "planes = planes[planes[\"manufacturingyear\"] != \"None\"]\n",
    "planes[\"manufacturingyear\"] = planes[\"manufacturingyear\"].astype(int)\n",
    "planes = planes[planes.manufacturingyear > 0] \n",
    "ageofplane = pd.merge(planes, ontime1[[\"arrdelay\",\"biarrdelay\",\"tailnum\"]], on=\"tailnum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b5c07",
   "metadata": {},
   "source": [
    "Group by manufacturing year and calculate the sum of frequency of arrival delay and the sum of arrival and no arrival delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a899650",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrdelayage = ageofplane.groupby(ageofplane[\"manufacturingyear\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelayage = ageofplane.groupby(ageofplane[\"manufacturingyear\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelayage = pd.DataFrame({\"manufacturingyear\":arrdelayage.index, \"biarrdelay\":arrdelayage.values})\n",
    "sumarrdelayage = pd.DataFrame({\"manufacturingyear\":sumarrdelayage.index, \"sumbiarrdelay\":sumarrdelayage.values})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4dbeb0",
   "metadata": {},
   "source": [
    "Add a new column arrdelayratio to compute the ratio of arrival delay. Divide the number of arrival delays by sum of arrival and no arrival delay for arrival delay ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "carrdelayage = pd.merge(arrdelayage,sumarrdelayage , on=\"manufacturingyear\")\n",
    "carrdelayage[\"arrdelayratio\"] = carrdelayage[\"biarrdelay\"]*1/carrdelayage[\"sumbiarrdelay\"]\n",
    "carrdelayage[\"arrdelayratio\"]  = carrdelayage[\"arrdelayratio\"].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e2a57",
   "metadata": {},
   "source": [
    "Scatter plot of ratio of arrival delays against manufacturing year is plotted. A line of best fit is fitted to demonstrate the relationship between of age of plane and arrival delay ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (12,12)\n",
    "sns.lmplot(x =\"manufacturingyear\", y = \"arrdelayratio\",\n",
    "           fit_reg = True, data = carrdelayage,line_kws={\"color\": \"blue\"}, ci = None, \n",
    "           markers=\"o\", scatter_kws = {\"color\":\"black\",\"facecolors\":\"none\"})\n",
    "plt.title(\"Arrival Delay based on Age of Planes\", \n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "plt.xlabel(\"Manufacturing Year\",fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.ylabel(\"Arrival Delay Ratio\",fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.xlim([1950, 2010])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764ae65",
   "metadata": {},
   "source": [
    "### b. Linear regression for demonstration of the linear relationship between age of plane and ratio of arrival delays.\n",
    "\n",
    "Identify the linear relationship between age of the plane, indicated by manufacturing year and the ratio of arrival delays. Manufacturing year is the predictor variable whereas arrival delay ratio is the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f30c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = carrdelayage[\"manufacturingyear\"]\n",
    "y = carrdelayage[\"arrdelayratio\"]\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548c1e7",
   "metadata": {},
   "source": [
    "# 3. How does the number of people flying between different locations change over time?\n",
    "\n",
    "### Idea: Investigate how the number of people change monthly from 2006 to 2007 between the destination city with highest number of inbound count and top 10 origin cities with highest number of outbound count to this destination city. This step is repeated with cities with 2nd and 3rd highest inbound count. The number of people is estimated with the number of outbound flights. Each flight is assumed to have 100 people.\n",
    "\n",
    "To compute the number of people between cities, canceled flights are excluded. To identify the top 3 destination cities with the highest number of inbound counts, destination cities are included in <code>topinbound</code>, which is the inner join of <code>ontime2</code>, which excluded canceled flights from <code>ontime</code> and <code>airports</code> by <code>dest</code> and <code>iata</code> columns. Then, group by destination cities and compute the inbound count for each city. Retain data of the top 3 cities with the highest number of inbound count which are Chicago, Atlanta and Dallas-Fort Worth for <code>topinbound</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime2 = ontime\n",
    "ontime2[\"cancelled\"] = ontime2[\"cancelled\"].apply(lambda x: str(x))\n",
    "ontime2 = ontime2[ontime2[\"cancelled\"] == \"0\"]\n",
    "\n",
    "airports2 = airports.rename(columns={\"iata\":\"dest\"}, inplace=False)\n",
    "topinbound = pd.merge(ontime2, airports2, on = \"dest\")\n",
    "topinbound = topinbound.groupby(\"city\")[\"city\"].count().sort_values(ascending = False).head(3)\n",
    "topinbound = pd.DataFrame({\"destcity\":topinbound.index, \"inboundcount\":topinbound.values})\n",
    "topinbound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45433249",
   "metadata": {},
   "source": [
    "<code>destorigin</code> is set up for origin and destination data. <code>ontime2</code> is joined with <code>airports</code> by <code>dest = iata</code>. Then, repeat this step with <code>origin = iata</code>. To ensure that <code>destorigin</code> only contains data from top 3 cities with highest inbound count, create <code>destorigin2</code> which is the inner join of <code>destorigin</code> and <code>topinbound</code>. Create a column called <code>ym</code>, by concatenating the values from the <code>year</code> and <code>month</code> columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "destorigin = ontime2[[\"datedeptime\", \"datearrtime\",\"year\",\"month\",\"origin\",\n",
    "         \"dest\",\"depdelay\",\"arrdelay\",\"tailnum\",\"biarrdelay\"]]\n",
    "destorigin = pd.merge(destorigin, airports2, on = \"dest\")\n",
    "destorigin.rename(columns={\"city\":\"destcity\",\"airport\":\"destairport\"}, inplace =  True)\n",
    "\n",
    "airports3 = airports.rename(columns={\"iata\":\"origin\"}, inplace=False)\n",
    "airports3 = airports3[[\"origin\",\"city\",\"airport\"]]\n",
    "destorigin = pd.merge(destorigin, airports3, on = \"origin\")\n",
    "destorigin.rename(columns={\"city\":\"origincity\",\"airport\":\"originairport\"}, inplace =  True)\n",
    "destorigin.drop([\"lat\",\"long\",\"state\"], axis=1, inplace=True)\n",
    "\n",
    "destorigin2 = pd.merge(destorigin, topinbound, on = \"destcity\")\n",
    "destorigin2[\"ym\"] = destorigin2[\"datedeptime\"].dt.strftime('%Y%m')\n",
    "destorigin2[\"ym2\"] = destorigin2[\"datedeptime\"].dt.strftime('%Y %b')\n",
    "\n",
    "destorigin2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2bd996",
   "metadata": {},
   "source": [
    "Create data frames <code>Chicago ,Atlanta , Dallas</code> with <code>ym , origin and destcity </code>columns. <code>Chicago</code> data frame should only contain data where destcity is Chicago, <code>Alanta</code> data frame should only contain data where destcity is Atlanta and <code>Dallas-Fort Worth</code> data frame should only contain data where destcity is Dallas. Store the data frames in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19354f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "for DESTCITYY in topinbound[\"destcity\"]:\n",
    "    dict1[DESTCITYY] = destorigin2[destorigin2[\"destcity\"] == DESTCITYY][[\"ym\",\"ym2\",\"origincity\",\"destcity\"]]\n",
    "    print(DESTCITYY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3398a301",
   "metadata": {},
   "source": [
    "To identify the top 10 origin cities with highest outbound count to Chicago, group by origin cities and compute the outbound count of each city. Ensure the destination city of destorigin only contains Chicago. This step is repeated for Atlanta and Dallas-Fort Worth with a for loop. The outputs of Chicago with top 10 origin cities, Atlanta with top 10 origin cities and Dallas with top 10 origin cities are stored as 3 new dataframes in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52205fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = {}\n",
    "for DESTCITYY in topinbound[\"destcity\"]:\n",
    "    dict2[DESTCITYY] = destorigin2[destorigin2[\"destcity\"] == DESTCITYY][[\"ym\",\"ym2\",\"origincity\",\"destcity\"]].groupby(\"origincity\")[\"origincity\"].count().sort_values(ascending = False).head(10)\n",
    "    print(DESTCITYY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ebf78",
   "metadata": {},
   "source": [
    "The data frames in <code> dict2</code> have no destcity columns. Merge them with data frames in <code>dict1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chicago = dict1.get(\"Chicago\")\n",
    "Chicago2 = dict2.get(\"Chicago\")\n",
    "Chicago2 = pd.DataFrame({\"origincity\":Chicago2.index, \"outboundcount\":Chicago2.values})\n",
    "Chicago2 = pd.merge(Chicago, Chicago2, on = \"origincity\")\n",
    "Chicago2 = Chicago2.sort_values(by=[\"outboundcount\"], ascending = False)\n",
    "\n",
    "Atlanta = dict1.get(\"Atlanta\")\n",
    "Atlanta2 = dict2.get(\"Atlanta\")\n",
    "Atlanta2 = pd.DataFrame({\"origincity\":Atlanta2.index, \"outboundcount\":Atlanta2.values})\n",
    "Atlanta2 = pd.merge(Atlanta, Atlanta2, on = \"origincity\")\n",
    "Atlanta2 = Atlanta2.sort_values(by=[\"outboundcount\"], ascending = False)\n",
    "\n",
    "Dallas = dict1.get(\"Dallas-Fort Worth\")\n",
    "Dallas2 = dict2.get(\"Dallas-Fort Worth\")\n",
    "Dallas2 = pd.DataFrame({\"origincity\":Dallas2.index, \"outboundcount\":Dallas2.values})\n",
    "Dallas2 = pd.merge(Dallas, Dallas2, on = \"origincity\")\n",
    "Dallas2 = Dallas2.sort_values(by=[\"outboundcount\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60cc9c5",
   "metadata": {},
   "source": [
    "To identify the monthly outbound count of each 10 origin cities to Chicago, group by destination cities, origin cities and ym for the computation of outbound count. The outbound count is then multiplied by 100 to represent the number of people. Repeat these step for Atlanta and Dallas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31c0e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Chicago3 = Chicago2.groupby([\"destcity\",\"origincity\",\"ym\",\"ym2\"]).size().reset_index()\n",
    "Chicago3.rename(columns={0:\"outboundcount\"}, inplace=True)\n",
    "Chicago3[\"peoplecount\"] = Chicago3[\"outboundcount\"]*100\n",
    "Chicago4 = (Chicago3.pivot_table(index=\"origincity\", columns=[\"ym\",\"ym2\"], values=\"peoplecount\",\n",
    "               aggfunc=\"sum\", margins=True).sort_values(\"All\", ascending=False).drop(\"All\", axis=1).drop(\"All\"))  \n",
    "\n",
    "Atlanta3 = Atlanta2.groupby([\"destcity\",\"origincity\",\"ym\",\"ym2\"]).size().reset_index()\n",
    "Atlanta3.rename(columns={0:\"outboundcount\"}, inplace=True)\n",
    "Atlanta3[\"peoplecount\"] = Atlanta3[\"outboundcount\"]*100\n",
    "Atlanta4 = (Atlanta3.pivot_table(index=\"origincity\", columns=[\"ym\",\"ym2\"], values=\"peoplecount\",\n",
    "               aggfunc=\"sum\", margins=True).sort_values(\"All\", ascending=False).drop(\"All\", axis=1).drop(\"All\"))\n",
    "\n",
    "Dallas3 = Dallas2.groupby([\"destcity\",\"origincity\",\"ym\",\"ym2\"]).size().reset_index()\n",
    "Dallas3.rename(columns={0:\"outboundcount\"}, inplace=True)\n",
    "Dallas3[\"peoplecount\"] = Dallas3[\"outboundcount\"]*100\n",
    "Dallas4 = (Dallas3.pivot_table(index=\"origincity\", columns=[\"ym\",\"ym2\"], values=\"peoplecount\",\n",
    "               aggfunc=\"sum\", margins=True).sort_values(\"All\", ascending=False).drop(\"All\", axis=1).drop(\"All\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28945d",
   "metadata": {},
   "source": [
    "Plot a heat map to depicts the number of people of each month of the year flying from top 10 origin cities to Chicago, Atlanta and Dallas-Fort Worth respectively from 2006 to 2007. Each rectangle demonstrates the number of people. YlGn color palettes is chosen for the heat map. Dark green represent higher number of people whereas light yellow illustrates lower number of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (20,8)\n",
    "ymlist = Chicago3.ym2.unique().tolist()\n",
    "ax = sns.heatmap(Chicago4,cmap = \"YlGn\", xticklabels = ymlist, cbar_kws={\"label\": \"Number of People\"},\n",
    "                 yticklabels= True)\n",
    "ax.set_xlabel(\"Period\", fontname = \"sans\", fontweight = \"light\",fontsize=10)\n",
    "ax.set_ylabel(\"Origin Cities\", fontname = \"sans\", fontweight = \"light\",fontsize=10)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontname = \"sans\", fontweight = \"light\", fontsize = 10)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels() , fontname = \"sans\", fontweight = \"light\", fontsize = 10)\n",
    "ax.figure.axes[-1].yaxis.label.set_size(10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize= 10)\n",
    "ax.set_title(\"Number of people from origin cities from 2006 to 2007 to \\nChicago\", \n",
    "           fontname = \"sans\", fontweight = \"bold\", fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (20,8)\n",
    "ymlist = Atlanta3.ym2.unique().tolist()\n",
    "ax = sns.heatmap(Atlanta4,cmap = \"YlGn\", xticklabels = ymlist, cbar_kws={\"label\": \"Number of People\"}, \n",
    "                 yticklabels= True)\n",
    "ax.set_xlabel(\"Period\", fontname = \"sans\", fontweight = \"light\",fontsize=10)\n",
    "ax.set_ylabel(\"Origin Cities\", fontname = \"sans\", fontweight = \"light\",fontsize=10)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontname = \"sans\", fontweight = \"light\", fontsize = 10)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels() , fontname = \"sans\", fontweight = \"light\", fontsize = 10)\n",
    "ax.figure.axes[-1].yaxis.label.set_size(10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize= 10)\n",
    "ax.set_title(\"Number of people from origin cities from 2006 to 2007 to \\n Atlanta\", \n",
    "           fontname = \"sans\", fontweight = \"bold\", fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (20,8)\n",
    "ymlist = Dallas3.ym2.unique().tolist()\n",
    "ax = sns.heatmap(Dallas4,cmap = \"YlGn\", xticklabels = ymlist, cbar_kws={\"label\": \"Number of People\"}, \n",
    "                 yticklabels= True)\n",
    "ax.set_xlabel(\"Period\", fontname = \"sans\", fontweight = \"light\",fontsize=10)\n",
    "ax.set_ylabel(\"Origin Cities\", fontname = \"sans\", fontweight = \"light\",fontsize=10)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontname = \"sans\", fontweight = \"light\", fontsize = 10)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels() , fontname = \"sans\", fontweight = \"light\", fontsize = 10)\n",
    "ax.figure.axes[-1].yaxis.label.set_size(10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize= 10)\n",
    "ax.set_title(\"Number of people from origin cities from 2006 to 2007 to\\n Dallas\", \n",
    "           fontname = \"sans\", fontweight = \"bold\", fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377781b",
   "metadata": {},
   "source": [
    "# 4. Can you detect cascading failures as delays in one airport create delays in others?\n",
    "\n",
    "### Idea: Study how departure delay of planes from an airport led to cascading arrival and departure delays of planes to other airports on the day where average arrival delay is the longest.\n",
    "\n",
    "To identify cascading failures, canceled and diverted flights are excluded. For origin and destination airports data, <code> destorigin3</code> is set up. Join <code>ontime1</code> from <code>ontime</code> which excludes canceled and diverted flights with <code>airports2 by <code>dest = iata </code>. Then, repeat this step with origin = iata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "destorigin3 = ontime1[[\"datedeptime\", \"datearrtime\",\"datecrsdeptime\", \"datecrsarrtime\", \"date\",\n",
    "         \"origin\",\"dest\",\"depdelay\",\"arrdelay\", \"tailnum\",\"flightnum\",\"biarrdelay\"]]\n",
    "destorigin3 = pd.merge(destorigin3, airports2, on = \"dest\")\n",
    "destorigin3.rename(columns={\"city\":\"destcity\",\"airport\":\"destairport\"}, inplace =  True)\n",
    "\n",
    "destorigin3 = pd.merge(destorigin3, airports3, on = \"origin\")\n",
    "destorigin3 = destorigin3[[\"datedeptime\", \"datearrtime\",\"datecrsdeptime\", \"datecrsarrtime\", \"date\",\n",
    "                           \"origin\",\"dest\",\"city\",\"destcity\",\"airport\",\"destairport\",\"depdelay\",\"arrdelay\", \n",
    "                           \"tailnum\",\"flightnum\",\"biarrdelay\"]]\n",
    "destorigin3.rename(columns={\"city\":\"origincity\",\"airport\":\"originairport\"}, inplace =  True)\n",
    "\n",
    "destorigin3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a1c39",
   "metadata": {},
   "source": [
    "Ensure that <code> destorigin4 </code> only contains the data from the date with the longest average arrival delay, which is on 2006-01-02. Arrange the data by tail number and actual departure time in ascending order. Ensure that arrival time is later than departure time, departure time is later than previous arrival time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxavgarrdelay = avgarrdelay.nlargest(1)\n",
    "maxavgarrdelay = pd.DataFrame({\"date\":maxavgarrdelay.index, \"avgarrdelay\":maxavgarrdelay.values})\n",
    "maxavgarrdelay = pd.DataFrame(np.repeat(maxavgarrdelay.values, destorigin3.shape[0], axis = 0))\n",
    "maxavgarrdelay.rename(columns = {0:\"date\" ,1:\"avgarrdelay\"}, inplace = True)\n",
    "\n",
    "destorigin4 = destorigin3[destorigin3[\"date\"] == maxavgarrdelay.date]\n",
    "\n",
    "destorigin4 = destorigin4[[\"date\",\"tailnum\",\"flightnum\",\"datecrsdeptime\",\"datecrsarrtime\",\n",
    "                          \"datedeptime\", \"datearrtime\", \"originairport\", \"destairport\",\n",
    "                          \"depdelay\",\"arrdelay\"]].sort_values([\"tailnum\",\"datedeptime\"], ascending = True)\n",
    "\n",
    "destorigin4 = destorigin4[destorigin4[\"datearrtime\"] > destorigin4[\"datedeptime\"]]\n",
    "\n",
    "destorigin4[\"lagdatearrtime\"] = destorigin4[\"datearrtime\"].shift(1)\n",
    "\n",
    "destorigin4 = destorigin4[destorigin4[\"datedeptime\"] > destorigin4[\"lagdatearrtime\"]]\n",
    "\n",
    "destorigin4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6b852",
   "metadata": {},
   "source": [
    "Select top 6 planes with highest number of flights on 2006-01-02. The top plane has 13 flights whereas the 2nd to 6th planes have 12 flights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a39388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "destorigin5 = destorigin4.groupby(destorigin4[\"tailnum\"])[\"arrdelay\"].count().sort_values(ascending = False).head(6)\n",
    "destorigin5 = pd.DataFrame({\"tailnum\":destorigin5.index, \n",
    "                                \"frequency\":destorigin5.values})\n",
    "destorigin5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baef478",
   "metadata": {},
   "source": [
    "Select data with only the top 6 planes.Filter the data such that only data with departure and arrival delay are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d5b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toptailnum = pd.merge(destorigin4, destorigin5, on = \"tailnum\")\n",
    "toptailnum2 = toptailnum[(toptailnum.depdelay > 0) & (toptailnum.arrdelay > 0)]\n",
    "toptailnum2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2015c1e",
   "metadata": {},
   "source": [
    "Create a dictionary for original data and another dictionary for data with departure and arrival delay. Each data frame in the dictionary contains data for each unique tail number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91784b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "toptailnumdict = {}\n",
    "for NUM in toptailnum[\"tailnum\"]:\n",
    "    toptailnumdict[NUM] = toptailnum[toptailnum[\"tailnum\"] == NUM]\n",
    "    \n",
    "toptailnumdict2 = {}\n",
    "for NUM in toptailnum2[\"tailnum\"]:\n",
    "    toptailnumdict2[NUM] = toptailnum2[toptailnum2[\"tailnum\"] == NUM] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18ca45",
   "metadata": {},
   "source": [
    "Identify planes with departure and arrival delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05d420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toptailnumdict2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681628bf",
   "metadata": {},
   "source": [
    "To study flights with cascading departure and arrival delay, compare the index of original data frames with filtered data frame and remove all rows below if there are missing index in the middle of the data frames.Row with missing index implies that plane did not have delay for that timing, hence breaking the cascading effect. The missing indexes are not in the middle of the data frames. Hence, no rows are needed to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98555a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N226SW_2 = toptailnumdict2.get(\"N226SW\")\n",
    "N271YV_2 = toptailnumdict2.get(\"N271YV\")\n",
    "N480HA_2 = toptailnumdict2.get(\"N480HA\")\n",
    "N226SW_1 = toptailnumdict.get(\"N226SW\")\n",
    "N271YV_1 = toptailnumdict.get(\"N271YV\")\n",
    "N480HA_1 = toptailnumdict.get(\"N480HA\")\n",
    "\n",
    "index1 = N226SW_1.index.difference(N226SW_2.index)\n",
    "index2 = N271YV_1.index.difference(N271YV_2.index)\n",
    "index3 = N480HA_1.index.difference(N480HA_2.index)\n",
    "print(index1,index2,index3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3600a",
   "metadata": {},
   "source": [
    "N226SW had more than 3 consecutive departure and arrival delays respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e825f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N226SW_2 = N226SW_2[[\"tailnum\", \"flightnum\",\"datecrsdeptime\",\"datedeptime\",\"datecrsarrtime\",\n",
    "         \"datearrtime\",\"originairport\",\"destairport\"]].reset_index() \n",
    "N226SW_2 = N226SW_2.iloc[: , 1:]\n",
    "N226SW_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9713580",
   "metadata": {},
   "source": [
    "N271YV had more than 3 consecutive departure and arrival delays respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4597270",
   "metadata": {},
   "outputs": [],
   "source": [
    "N271YV_2 = N271YV_2[[\"tailnum\", \"flightnum\",\"datecrsdeptime\",\"datedeptime\",\"datecrsarrtime\",\n",
    "         \"datearrtime\",\"originairport\",\"destairport\"]].reset_index() \n",
    "N271YV_2 = N271YV_2.iloc[: , 1:]\n",
    "N271YV_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0a39f",
   "metadata": {},
   "source": [
    "N480HA has less than 3 consecutive departure and arrival delays respectively. Hence, it is not selected for the study of cascading failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ab859",
   "metadata": {},
   "outputs": [],
   "source": [
    "N480HA_2 = N480HA_2[[\"tailnum\", \"flightnum\",\"datecrsdeptime\",\"datedeptime\",\"datecrsarrtime\",\n",
    "         \"datearrtime\",\"originairport\",\"destairport\"]].reset_index() \n",
    "N480HA_2 = N480HA_2.iloc[: , 1:]\n",
    "N480HA_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecdc95",
   "metadata": {},
   "source": [
    "Create edge list for N226SW.Group by edges to compute the number of connections between 2 nodes. Store the output of the number of connections in a new column called <code> weight </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f59a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "N226SW_2[\"edges\"] = N226SW_2[[\"originairport\",\"destairport\"]].apply(tuple, axis = 1)\n",
    "N226SW_3 = N226SW_2.groupby([\"edges\"]).size().sort_values(ascending = False)\n",
    "N226SW_3 = pd.DataFrame({\"edges\":N226SW_3 .index, \"weight\":N226SW_3 .values})\n",
    "N226SW_3[\"originairport\"], N226SW_3[\"destairport\"] = N226SW_3.edges.str\n",
    "N226SW_3 = N226SW_3[[\"originairport\",\"destairport\",\"weight\"]]\n",
    "N226SW_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c36c2",
   "metadata": {},
   "source": [
    "Create a directed graph for cascading failures of N226SW on 2006-01-02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24455070",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()  \n",
    "\n",
    "for index, row in N226SW_3.iterrows():\n",
    "    G.add_edge(row[\"originairport\"], row[\"destairport\"], weight=row[\"weight\"], color = \"#808080\")\n",
    "  \n",
    "remove = [node for node,degree in G.degree() if degree ==0]\n",
    "G.remove_nodes_from(remove)\n",
    "\n",
    "colors = nx.get_edge_attributes(G,\"color\").values()\n",
    "\n",
    "weights = nx.get_edge_attributes(G,\"weight\").values()\n",
    "weights = np.divide(list(weights),(1/3))\n",
    "\n",
    "options = {\n",
    "     \"node_color\": \"#f03b20\",\n",
    "     \"alpha\": 1,\n",
    "     \"connectionstyle\": \"arc3, rad=0.1\"} \n",
    "\n",
    "plt.subplots(figsize=(10,5))\n",
    "\n",
    "pos=nx.spring_layout(G)\n",
    "\n",
    "d = dict(G.degree(weight=\"weight\"))\n",
    "\n",
    "nx.draw(G, pos=pos, \n",
    "        nodelist=list(d.keys()), \n",
    "        node_size=[v*1000 for v in d.values()],  \n",
    "        width=weights, edge_color=colors, **options)\n",
    "nx.draw_networkx_labels(G, pos=pos, font_size = 12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.title(\"Cascading failures of N226SW on 2006-01-02\", \n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d336b9f",
   "metadata": {},
   "source": [
    "Create edge list for N271YV. Group by edges to compute the number of connections between 2 nodes. Store the output of the number of connections in a new column called <code> weight </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc63656",
   "metadata": {},
   "outputs": [],
   "source": [
    "N271YV_2[\"edges\"] = N271YV_2[[\"originairport\",\"destairport\"]].apply(tuple, axis = 1)\n",
    "N271YV_3 = N271YV_2.groupby([\"edges\"]).size().sort_values(ascending = False)\n",
    "N271YV_3 = pd.DataFrame({\"edges\":N271YV_3 .index, \"weight\":N271YV_3 .values})\n",
    "N271YV_3[\"originairport\"], N271YV_3[\"destairport\"] = N271YV_3.edges.str\n",
    "N271YV_3 = N271YV_3[[\"originairport\",\"destairport\",\"weight\"]]\n",
    "N271YV_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f23bd4",
   "metadata": {},
   "source": [
    "Create a directed graph for cascading failures of N271YV on 2006-01-02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4605f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.DiGraph()  \n",
    "\n",
    "for index, row in N271YV_3.iterrows():\n",
    "    G2.add_edge(row[\"originairport\"], row[\"destairport\"], weight=row[\"weight\"], color = \"#808080\")\n",
    "  \n",
    "remove = [node for node,degree in G2.degree() if degree ==0]\n",
    "G2.remove_nodes_from(remove)\n",
    "\n",
    "colors = nx.get_edge_attributes(G2,\"color\").values()\n",
    "\n",
    "weights = nx.get_edge_attributes(G2,\"weight\").values()\n",
    "weights = np.divide(list(weights),(1/5))\n",
    "\n",
    "options = {\n",
    "     \"node_color\": \"#fecc5c\",\n",
    "     \"alpha\": 1,\n",
    "     \"connectionstyle\": \"arc3, rad=0.1\"} \n",
    "\n",
    "plt.subplots(figsize=(10,5))\n",
    "\n",
    "pos=nx.spring_layout(G2)\n",
    "\n",
    "d = dict(G2.degree(weight=\"weight\"))\n",
    "\n",
    "nx.draw(G2, pos=pos, \n",
    "        nodelist=list(d.keys()), \n",
    "        node_size=[v*850 for v in d.values()],  \n",
    "        width=weights, edge_color=colors, **options)\n",
    "nx.draw_networkx_labels(G2, pos=pos, font_size = 12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.title(\"Cascading failures of N271YV on 2006-01-02\", \n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff826a",
   "metadata": {},
   "source": [
    "# 5. Use available variables to construct a model that predicts delays\n",
    "\n",
    "### Idea: A target variable is chosen and exploratory data analysis is conducted for features selection. Data is sampled to process datasets. Different classification models are trained with training sets and their performance is evaluated by running the trained models on test sets. Grid search with cross validations are conducted using training set for hyperparameter optimisation. ROC curves are used as a measure to compare performance of the classification models. \n",
    "\n",
    "### a. Exploratory data analysis\n",
    "\n",
    "Explore the relationship between scheduled departure time and arrival delay ratio. Compute arrival delay ratio for each scheduled departure time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrdelaydeptime = ontime1.groupby(ontime1[\"crsdeptimeintervals\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelaydeptime = ontime1.groupby(ontime1[\"crsdeptimeintervals\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelaydeptime = pd.DataFrame({\"crsdeptimeintervals\":arrdelaydeptime.index, \"biarrdelay\":arrdelaydeptime.values})\n",
    "sumarrdelaydeptime = pd.DataFrame({\"crsdeptimeintervals\":sumarrdelaydeptime.index, \"sumbiarrdelay\":sumarrdelaydeptime.values})\n",
    "\n",
    "carrdelaydeptime = pd.merge(arrdelaydeptime, sumarrdelaydeptime , on=\"crsdeptimeintervals\")\n",
    "carrdelaydeptime[\"arrdelayratio\"] = carrdelaydeptime[\"biarrdelay\"]*1/carrdelaydeptime[\"sumbiarrdelay\"]\n",
    "carrdelaydeptime[\"arrdelayratio\"]  = carrdelaydeptime[\"arrdelayratio\"].apply(lambda x: round(x, 2))\n",
    "carrdelaydeptime = carrdelaydeptime.sort_values(\"arrdelayratio\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(carrdelaydeptime.crsdeptimeintervals,carrdelaydeptime.arrdelayratio, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Arrival Delay Ratio based on \\n Scheduled Departure Time Intervals\", fontname = \"sans\",\n",
    "             fontweight = \"bold\", fontsize = 20)\n",
    "ax.set_xlabel(\"Scheduled Departure Time Intervals\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.set_ylabel(\"Arrival Delay Ratio\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "\n",
    "plt.xticks(rotation = 45, ha=\"right\", rotation_mode=\"anchor\",\n",
    "          fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5326596",
   "metadata": {},
   "source": [
    "Explore the relationship between scheduled arrival time and arrival delay ratio. Compute arrival delay ratio for each scheduled arrival time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrdelayarrtime = ontime1.groupby(ontime1[\"crsarrtimeintervals\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelayarrtime = ontime1.groupby(ontime1[\"crsarrtimeintervals\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelayarrtime = pd.DataFrame({\"crsarrtimeintervals\":arrdelayarrtime.index, \"biarrdelay\":arrdelayarrtime.values})\n",
    "sumarrdelayarrtime = pd.DataFrame({\"crsarrtimeintervals\":sumarrdelayarrtime.index, \"sumbiarrdelay\":sumarrdelayarrtime.values})\n",
    "\n",
    "carrdelayarrtime = pd.merge(arrdelayarrtime, sumarrdelayarrtime , on = \"crsarrtimeintervals\")\n",
    "carrdelayarrtime[\"arrdelayratio\"] = carrdelayarrtime[\"biarrdelay\"]*1/carrdelayarrtime[\"sumbiarrdelay\"]\n",
    "carrdelayarrtime[\"arrdelayratio\"]  = carrdelayarrtime[\"arrdelayratio\"].apply(lambda x: round(x, 2))\n",
    "carrdelayarrtime = carrdelayarrtime.sort_values(\"arrdelayratio\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ed5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(carrdelayarrtime.crsarrtimeintervals,carrdelayarrtime.arrdelayratio, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Arrival Delay Ratio \\nbased on Scheduled Arrival Time Intervals\", fontname = \"sans\", \n",
    "             fontweight = \"bold\", \n",
    "             fontsize = 20)\n",
    "ax.set_xlabel(\"Scheduled Arrival Time Intervals\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.set_ylabel(\"Arrival Delay Ratio\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "\n",
    "plt.xticks(rotation = 45, ha=\"right\", rotation_mode=\"anchor\",\n",
    "          fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94112a17",
   "metadata": {},
   "source": [
    "Explore the relationship between carrier and arrival delay ratio. Compute arrival delay ratio for each carrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "carriers = carriers.rename(columns = str.lower)\n",
    "carriers.rename(columns = {\"code\":\"uniquecarrier\"}, inplace = True)\n",
    "\n",
    "carrierdelay = pd.merge(ontime1, carriers, on = \"uniquecarrier\")\n",
    "\n",
    "arrdelaycarrier = carrierdelay.groupby(carrierdelay[\"description\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelaycarrier = carrierdelay.groupby(carrierdelay[\"description\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelaycarrier = pd.DataFrame({\"carrier\":arrdelaycarrier.index, \"biarrdelay\":arrdelaycarrier.values})\n",
    "sumarrdelaycarrier = pd.DataFrame({\"carrier\":sumarrdelaycarrier.index, \"sumbiarrdelay\":sumarrdelaycarrier.values})\n",
    "\n",
    "carrdelaycarrier = pd.merge(arrdelaycarrier, sumarrdelaycarrier , on=\"carrier\")\n",
    "carrdelaycarrier[\"arrdelayratio\"] = carrdelaycarrier[\"biarrdelay\"]*1/carrdelaycarrier[\"sumbiarrdelay\"]\n",
    "carrdelaycarrier[\"arrdelayratio\"]  = carrdelaycarrier[\"arrdelayratio\"].apply(lambda x: round(x, 2))\n",
    "\n",
    "carrdelaycarrier2 = carrdelaycarrier.sort_values(\"arrdelayratio\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af96b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(carrdelaycarrier2.carrier,carrdelaycarrier2.arrdelayratio, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Arrival Delay Ratio based on Carriers\", fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "ax.set_xlabel(\"Carriers\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.set_ylabel(\"Arrival Delay Ratio\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "\n",
    "\n",
    "plt.xticks(rotation = 45, ha=\"right\", rotation_mode=\"anchor\",\n",
    "          fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07902a8b",
   "metadata": {},
   "source": [
    "Explore the relationship between destination airport and arrival delay ratio. Compute arrival delay ratio for each destination airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1da5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrdelayda = destorigin3.groupby(destorigin3[\"destairport\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelayda = destorigin3.groupby(destorigin3[\"destairport\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelayda = pd.DataFrame({\"destairport\":arrdelayda.index, \"biarrdelay\":arrdelayda.values})\n",
    "sumarrdelayda = pd.DataFrame({\"destairport\":sumarrdelayda.index, \"sumbiarrdelay\":sumarrdelayda.values})\n",
    "\n",
    "carrdelayda = pd.merge(arrdelayda, sumarrdelayda , on = \"destairport\")\n",
    "carrdelayda[\"arrdelayratio\"] = carrdelayda[\"biarrdelay\"]*1/carrdelayda[\"sumbiarrdelay\"]\n",
    "carrdelayda[\"arrdelayratio\"]  = carrdelayda[\"arrdelayratio\"].apply(lambda x: round(x, 2))\n",
    "\n",
    "carrdelayda2 = carrdelayda.sort_values(\"arrdelayratio\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(carrdelayda2.destairport,carrdelayda2.arrdelayratio, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Arrival Delay Ratio based on Destination Airport\", fontname = \"sans\", fontweight = \"bold\", \n",
    "             fontsize = 20)\n",
    "ax.set_xlabel(\"Destination Airport\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.set_ylabel(\"Arrival Delay Ratio\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "\n",
    "\n",
    "plt.xticks(rotation = 45, ha=\"right\", rotation_mode=\"anchor\",\n",
    "          fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5822453",
   "metadata": {},
   "source": [
    "Explore the relationship between origin airport and arrival delay ratio. Compute arrival delay ratio for each origin airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95629bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrdelayoa = destorigin3.groupby(destorigin3[\"originairport\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelayoa = destorigin3.groupby(destorigin3[\"originairport\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelayoa = pd.DataFrame({\"originairport\":arrdelayoa.index, \"biarrdelay\":arrdelayoa.values})\n",
    "sumarrdelayoa = pd.DataFrame({\"originairport\":sumarrdelayoa.index, \"sumbiarrdelay\":sumarrdelayoa.values})\n",
    "\n",
    "carrdelayoa = pd.merge(arrdelayoa, sumarrdelayoa , on = \"originairport\")\n",
    "carrdelayoa[\"arrdelayratio\"] = carrdelayoa[\"biarrdelay\"]*1/carrdelayoa[\"sumbiarrdelay\"]\n",
    "carrdelayoa[\"arrdelayratio\"]  = carrdelayoa[\"arrdelayratio\"].apply(lambda x: round(x, 2))\n",
    "\n",
    "carrdelayoa2 = carrdelayoa.sort_values(\"arrdelayratio\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b82ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(carrdelayoa2.originairport,carrdelayoa2.arrdelayratio, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Arrival Delay Ratio based on Origin Airport\", fontname = \"sans\", fontweight = \"bold\", \n",
    "             fontsize = 20)\n",
    "ax.set_xlabel(\"Origin Airport\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.set_ylabel(\"Arrival Delay Ratio\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "\n",
    "\n",
    "plt.xticks(rotation = 45, ha=\"right\", rotation_mode=\"anchor\",\n",
    "          fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5c544",
   "metadata": {},
   "source": [
    "Explore the relationship between month and arrival delay ratio. Compute arrival delay ratio for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf525d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime1[\"month2\"] = ontime1[\"month\"].astype(int)\n",
    "ontime1[\"month2\"] = ontime1[\"month2\"].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "arrdelaymonth= ontime1.groupby(ontime1[\"month2\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelaymonth = ontime1.groupby(ontime1[\"month2\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelaymonth = pd.DataFrame({\"month\":arrdelaymonth.index, \"biarrdelay\":arrdelaymonth.values})\n",
    "sumarrdelaymonth = pd.DataFrame({\"month\":sumarrdelaymonth.index, \"sumbiarrdelay\":sumarrdelaymonth.values})\n",
    "\n",
    "carrdelaymonth = pd.merge(arrdelaymonth, sumarrdelaymonth , on = \"month\")\n",
    "carrdelaymonth[\"arrdelayratio\"] = carrdelaymonth[\"biarrdelay\"]*1/carrdelaymonth[\"sumbiarrdelay\"]\n",
    "carrdelaymonth[\"arrdelayratio\"]  = carrdelaymonth[\"arrdelayratio\"].apply(lambda x: round(x, 2))\n",
    "carrdelaymonth = carrdelaymonth.sort_values(\"arrdelayratio\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(carrdelaymonth.month,carrdelaymonth.arrdelayratio, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Arrival Delay Ratio based on Month\", fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "ax.set_xlabel(\"Month\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.set_ylabel(\"Arrival Delay Ratio\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831f7d6",
   "metadata": {},
   "source": [
    "Explore the relationship between day of week and arrival delay ratio. Compute arrival delay ratio for each day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime1[\"dayofweek2\"] = ontime1[\"dayofweek\"].astype(int)\n",
    "ontime1[\"dayofweek2\"] = ontime1[\"dayofweek2\"]-1\n",
    "ontime1[\"dayofweek2\"] = ontime1[\"dayofweek2\"].apply(lambda x: calendar.day_abbr[x])\n",
    "\n",
    "arrdelaydow = ontime1.groupby(ontime1[\"dayofweek2\"])[\"biarrdelay\"].sum()\n",
    "sumarrdelaydow  = ontime1.groupby(ontime1[\"dayofweek2\"])[\"biarrdelay\"].count()\n",
    "\n",
    "arrdelaydow = pd.DataFrame({\"dayofweek\":arrdelaydow.index, \"biarrdelay\":arrdelaydow.values})\n",
    "sumarrdelaydow = pd.DataFrame({\"dayofweek\":sumarrdelaydow.index, \"sumbiarrdelay\":sumarrdelaydow.values})\n",
    "\n",
    "carrdelaydow = pd.merge(arrdelaydow , sumarrdelaydow , on=\"dayofweek\")\n",
    "carrdelaydow[\"arrdelayratio\"] = carrdelaydow[\"biarrdelay\"]*1/carrdelaydow[\"sumbiarrdelay\"]\n",
    "carrdelaydow[\"arrdelayratio\"]  = carrdelaydow[\"arrdelayratio\"].apply(lambda x: round(x, 2))\n",
    "carrdelaydow = carrdelaydow.sort_values(\"arrdelayratio\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fe014",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "col_map = plt.get_cmap(\"Paired\")\n",
    "\n",
    "ax.bar(carrdelaydow.dayofweek,carrdelaydow.arrdelayratio, color = col_map.colors, \n",
    "       edgecolor = \"white\", width = 0.8)\n",
    "ax.set_title(\"Arrival Delay Ratio based on Day of Week\", fontname = \"sans\", fontweight = \"bold\", fontsize = 20)\n",
    "ax.set_xlabel(\"Day of Week\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.set_ylabel(\"Arrival Delay Ratio\", fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "# addlabels(carrdelaycarrier2.carrier,carrdelaycarrier2.arrdelayratio)\n",
    "\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb1658",
   "metadata": {},
   "source": [
    "### b. Target variable and features selection\n",
    "\n",
    "The target variable is <code>biarrdelay</code>. If the arrival delay, <code>arrdelay</code> is more than 0, <code>biarrdelay</code> = 1. Else, <code>biarrdelay</code> = 0. Based on exploratory data analysis, the features such as <code>crsdeptimeintervals, crsarrtimeintervals, description, destairport, originairport, month, dayofweek</code> are chosen as they have influence on the outcome of <code>biarrdelay</code>. \n",
    "\n",
    "A dataframe, <code>ontime3</code> is set up by filtering out canceled and diverted flights from ontime and containing all the features and target variable needed for predictive modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime3 = ontime[ontime[\"cancelled\"] == 0]\n",
    "ontime3 = ontime[ontime[\"diverted\"] == 0]\n",
    "ontime3 = pd.merge(ontime3, airports2, on = \"dest\")\n",
    "ontime3 = pd.merge(ontime3, carriers, on = \"uniquecarrier\")\n",
    "ontime3 = ontime3[[\"biarrdelay\",\"crsdeptimeintervals\",\"crsarrtimeintervals\", \"description\", \"airport\",\n",
    "                   \"month\", \"dayofweek\", \"origin\"]]\n",
    "ontime3.rename(columns = {\"description\": \"carrier\", \"airport\": \"destairport\"}, inplace = True)\n",
    "\n",
    "ontime3 = pd.merge(ontime3, airports3, on = \"origin\")\n",
    "ontime3 = ontime3[[\"biarrdelay\",\"crsdeptimeintervals\",\"crsarrtimeintervals\", \"carrier\", \"airport\",\"destairport\", \n",
    "                   \"month\", \"dayofweek\"]]\n",
    "ontime3.rename(columns = {\"description\": \"carrier\", \"airport\": \"originairport\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb245e59",
   "metadata": {},
   "source": [
    "### c. Sampled data from original data\n",
    "\n",
    "The data from 2006 to 2007 of approximately 14 million rows. 20% of the data is sampled such that the distribution of the all variables of the sampled data is the same with original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff17f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime4 = ontime3.sample(int(len(ontime3)*0.2))\n",
    "ontime4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500ff5e",
   "metadata": {},
   "source": [
    "Add new column in <code>ontime3</code> and <code>ontime4</code> with character \"original\" and \"sample\" respectively. Bind them by rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162063ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime3[\"char\"] = \"original\"\n",
    "ontime4[\"char\"] = \"sample\"\n",
    "ontime4b = ontime3.append(ontime4)\n",
    "ontime4b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca5af3",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for scheduled departure time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00237b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ontime4b.groupby([\"crsdeptimeintervals\",\"char\"]).count()\n",
    "counts = counts.iloc[:,0:1]\n",
    "\n",
    "totals = counts.sum(level=0)\n",
    "\n",
    "counts = counts.unstack(level=1)\n",
    "counts.columns = counts.columns.droplevel(level=0)\n",
    "counts\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "crsdeptimeintervals = ontime4b.crsdeptimeintervals.unique()\n",
    "plt.bar(crsdeptimeintervals, counts[\"sample\"], bottom=None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(crsdeptimeintervals, counts[\"original\"], bottom = counts[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation = 45, ha=\"right\", rotation_mode=\"anchor\",\n",
    "          fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.xlabel(\"Scheduled Departure Time Intervals\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f90b1",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for scheduled arrival time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2 = ontime4b.groupby([\"crsarrtimeintervals\",\"char\"]).count()\n",
    "counts2 = counts2.iloc[:,0:1]\n",
    "\n",
    "totals2 = counts2.sum(level=0)\n",
    "\n",
    "counts2 = counts2.unstack(level=1)\n",
    "counts2.columns = counts2.columns.droplevel(level=0)\n",
    "counts2\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "crsarrtimeintervals = ontime4b.crsarrtimeintervals.unique().astype(str)\n",
    "plt.bar(crsarrtimeintervals ,counts2[\"sample\"], bottom = None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(crsarrtimeintervals, counts2[\"original\"], bottom = counts2[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Scheduled Arrival Time Intervals\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4fdb2",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for carrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2362e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts3 = ontime4b.groupby([\"carrier\",\"char\"]).count()\n",
    "counts3 = counts3.iloc[:,0:1]\n",
    "\n",
    "totals3 = counts3.sum(level=0)\n",
    "\n",
    "counts3 = counts3.unstack(level=1)\n",
    "counts3.columns = counts3.columns.droplevel(level=0)\n",
    "counts3\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "carrier = ontime4b.carrier.unique()\n",
    "plt.bar(carrier, counts3[\"sample\"], bottom=None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(carrier, counts3[\"original\"], bottom = counts3[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data (Carrier)\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.axes.xaxis.set_visible(False)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b509e5",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for destination airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b67405",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts4 = ontime4b.groupby([\"destairport\",\"char\"]).count()\n",
    "counts4 = counts4.iloc[:,0:1]\n",
    "\n",
    "totals4 = counts4.sum(level=0)\n",
    "\n",
    "counts4 = counts4.unstack(level=1)\n",
    "counts4.columns = counts4.columns.droplevel(level=0)\n",
    "counts4\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "destairport = ontime4b.destairport.unique()\n",
    "plt.bar(destairport, counts4[\"sample\"], bottom=None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(destairport, counts4[\"original\"], bottom = counts4[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data (Destination Airport)\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.axes.xaxis.set_visible(False)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a903e",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for origin airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts4b = ontime4b.groupby([\"originairport\",\"char\"]).count()\n",
    "counts4b = counts4b.iloc[:,0:1]\n",
    "\n",
    "totals4b = counts4b.sum(level=0)\n",
    "\n",
    "counts4b = counts4b.unstack(level=1)\n",
    "counts4b.columns = counts4b.columns.droplevel(level=0)\n",
    "counts4b\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "originairport = ontime4b.originairport.unique()\n",
    "plt.bar(originairport, counts4b[\"sample\"], bottom=None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(originairport, counts4b[\"original\"], bottom = counts4b[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data (Origin Airport)\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.axes.xaxis.set_visible(False)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4656ca",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d966645",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts5 = ontime4b.groupby([\"month\",\"char\"]).count()\n",
    "counts5 = counts5.iloc[:,0:1]\n",
    "\n",
    "totals5 = counts5.sum(level=0)\n",
    "\n",
    "counts5 = counts5.unstack(level=1)\n",
    "counts5.columns = counts5.columns.droplevel(level=0)\n",
    "counts5\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "month = ontime4b.month.unique()\n",
    "plt.bar(month, counts5[\"sample\"], bottom=None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(month, counts5[\"original\"], bottom = counts5[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Month\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox = False, shadow = False)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "month2 = [\"Jan\",\"Feb\",\"Mar\",\"April\",\"May\",\"June\",\"July\",\"Aug\",\"Sept\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "ax.set_xticklabels(month2, minor=False, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beecf2f",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952f289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts6 = ontime4b.groupby([\"dayofweek\",\"char\"]).count()\n",
    "counts6 = counts6.iloc[:,0:1]\n",
    "\n",
    "totals6 = counts6.sum(level=0)\n",
    "\n",
    "counts6 = counts6.unstack(level=1)\n",
    "counts6.columns = counts6.columns.droplevel(level=0)\n",
    "counts6\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "dayofweek = ontime4b.dayofweek.unique()\n",
    "plt.bar(dayofweek, counts6[\"sample\"], bottom=None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(dayofweek, counts6[\"original\"], bottom = counts6[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Day of Week\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "dayofweek2 = [\"0\",\"Mon\",\"Tue\",\"Wed\",\"Thurs\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "ax.set_xticklabels(dayofweek2, minor=False, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81bc48",
   "metadata": {},
   "source": [
    "Plot the distribution of original versus sampled data for arrival delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts7 = ontime4b.groupby([\"biarrdelay\",\"char\"]).count()\n",
    "counts7 = counts7.iloc[:,0:1]\n",
    "\n",
    "totals7 = counts7.sum(level=0)\n",
    "\n",
    "counts7 = counts7.unstack(level=1)\n",
    "counts7.columns = counts7.columns.droplevel(level=0)\n",
    "counts7\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "biarrdelay = ontime4b.biarrdelay.unique()\n",
    "plt.bar(biarrdelay, counts7[\"sample\"], bottom=None, color= \"#1F78B4\", label= \"sample\")\n",
    "plt.bar(biarrdelay, counts7[\"original\"], bottom = counts7[\"sample\"], color=\"#A6CEE3\", label= \"original\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Arrival Delay\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.ylabel(\"Count\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Distribution of Original versus Sampled Data\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "          fancybox = False, shadow = False, fontsize = 15)\n",
    "plt.locator_params(nbins=2)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d83fce",
   "metadata": {},
   "source": [
    "### d. Pre-processing for predictive modelling\n",
    "\n",
    "Convert categorical variables to dummy variables. Multicollinearity issues could be avoided by removing the last dummy of every variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime5 = ontime4[[\"biarrdelay\",\"crsdeptimeintervals\",\"crsarrtimeintervals\", \"carrier\", \"destairport\", \"originairport\",\n",
    "            \"month\", \"dayofweek\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad87104",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime5[\"dayofweek\"] = pd.Categorical(ontime5.dayofweek)\n",
    "ontime5[\"month\"] = pd.Categorical(ontime5.dayofweek)\n",
    "ontime5 = pd.get_dummies(ontime5, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e33f58a",
   "metadata": {},
   "source": [
    "Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67101f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ontime5.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64acb40",
   "metadata": {},
   "source": [
    "Select target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ontime5.iloc[:, 0]\n",
    "y = y.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a870a9e",
   "metadata": {},
   "source": [
    "Select 75% of the sampled data randomly as the training set, the rest of 25% of the data is used as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1de357",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f12eb",
   "metadata": {},
   "source": [
    "# e. Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08610d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 10000, penalty='none')\n",
    "lr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b8bdf",
   "metadata": {},
   "source": [
    "### Penalised Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plr = LogisticRegression(penalty='l1', max_iter = 10000, tol=0.01, solver='saga')\n",
    "plr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542b3df",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac856c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb = GradientBoostingClassifier(random_state = 2)\n",
    "gdb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e654c",
   "metadata": {},
   "source": [
    "### Classfication Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = DecisionTreeClassifier(random_state=0)\n",
    "ct.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9effa30d",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1aa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad896b9",
   "metadata": {},
   "source": [
    "Use grid search with cross validations to identify optimal hyperparamter of the model for most accurate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ac01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [50, 150, 300, 600]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83fa1f2",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fadf60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,8))\n",
    "ax = plt.gca()\n",
    "\n",
    "plot_roc_curve(lr, X_test, y_test, ax=ax, name='Logistic Regression')\n",
    "plot_roc_curve(plr, X_test, y_test, ax=ax, name='Penalised logistic regression')\n",
    "plot_roc_curve(gdb, X_test, y_test, ax=ax, name='Gradient Boosting')\n",
    "plot_roc_curve(ct, X_test, y_test, ax=ax, name='Classification trees')\n",
    "plot_roc_curve(rf, X_test, y_test, ax=ax, name='Random forests')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')\n",
    "plt.legend(fontsize = 10)\n",
    "plt.xlabel(\"False Positive Rate\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.ylabel(\"True Positive Rate\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.title(\"Comparison of Performance of Classification Models by ROC Curve\",\n",
    "          fontname = \"sans\", fontweight = \"bold\", fontsize = 15)\n",
    "plt.xticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "plt.yticks(fontname = \"sans\", fontweight = \"light\", fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b10fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
